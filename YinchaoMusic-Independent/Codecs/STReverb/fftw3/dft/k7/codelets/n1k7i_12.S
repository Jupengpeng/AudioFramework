/*
 * Copyright (c) 2003, 2006 Matteo Frigo
 * Copyright (c) 2003, 2006 Massachusetts Institute of Technology
 *
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 *
 */

/* This file was automatically generated --- DO NOT EDIT */
/* Generated on Sat Jul  1 22:43:14 EDT 2006 */

#include "config.h"



/* cheap-mode: VECTGRADE_FULL succeeded. (163 steps) */
/* Generated by: ../../../genfft-k7/gen_notw -no-randomized-cse -n 12 -sign 1 -name n1k7i_12 */

/*
 * Generator Id's : 
 * $Id: algsimp.ml,v 1.4 2006-01-05 03:04:27 stevenj Exp $
 * $Id: fft.ml,v 1.4 2006-01-05 03:04:27 stevenj Exp $
 * $Id: gen_notw.ml,v 1.12 2006-01-05 03:04:27 stevenj Exp $
 */

/* CHImovopt_applicable: new! */
/* CHImovopt_applicable: new! */
/* CHImovopt_applicable: new! */
/* The following asm code is Copyright (c) 2000-2001 Stefan Kral */
.section .rodata
	.balign 64
KP866025403KN866025403: .float +0.866025403784438646763723170752936183471402627, -0.866025403784438646763723170752936183471402627
KP500000000KP500000000: .float +0.500000000000000000000000000000000000000000000, +0.500000000000000000000000000000000000000000000
chs_lo: .long 0x80000000, 0x00000000
.text
.text
	.balign 64
n1k7i_12:
	subl $76, %esp
	femms 
	movl %ebx, 72(%esp)
	movl 96(%esp), %edx
	movl 100(%esp), %ebx
	movl 84(%esp), %eax
	movl %esi, 68(%esp)
	movl 92(%esp), %ecx
	movl %edi, 64(%esp)
	sall $2, 108(%esp)
	movl %ebp, 60(%esp)
	sall $2, 112(%esp)
	leal (,%edx,4), %edx
	leal (,%ebx,4), %ebx
	.p2align 4,,7
.L0:
	/* promise simd cell size = 8 */ 
	movq (%eax,%edx,8), %mm0
	movq (%eax,%edx,4), %mm1
	leal (%edx,%edx,4), %esi
	movq (%eax,%edx,2), %mm3
	leal (%edx,%edx,2), %edi
	movq (%eax), %mm6
	movq (%eax,%esi,2), %mm4
	leal (%esi,%edx,2), %ebp
	movq %mm1, %mm2
	pfsubr %mm0, %mm1
	pfadd %mm0, %mm2
	movq (%eax,%edi,2), %mm0
	movq %mm6, %mm7
	movq %mm4, %mm5
	pfadd %mm3, %mm4
	leal (%edx,%edx,8), %edi
	pswapd %mm1, %mm1
	pfsubr %mm3, %mm5
	pfmul KP866025403KN866025403, %mm1
	movq %mm0, %mm3
	pfadd %mm2, %mm6
	pfadd %mm4, %mm0
	pfmul KP500000000KP500000000, %mm4
	pfmul KP500000000KP500000000, %mm2
	pswapd %mm5, %mm5
	pfmul KP866025403KN866025403, %mm5
	movq %mm1, 0(%esp)
	movq (%eax,%edx), %mm1
	pfsub %mm4, %mm3
	movq (%eax,%esi), %mm4
	leal (%ebp,%edx,4), %esi
	pfsub %mm2, %mm7
	movq %mm1, %mm2
	movq %mm5, 32(%esp)
	pfsub %mm4, %mm1
	movq (%eax,%esi), %mm5
	pfadd %mm4, %mm2
	movq %mm7, 16(%esp)
	movq (%eax,%ebp), %mm4
	leal (%edx,%edx,2), %ebp
	leal (%ebx,%ebx,2), %esi
	pfmul KP866025403KN866025403, %mm1
	movq %mm4, %mm7
	pfsub %mm5, %mm4
	pfadd %mm5, %mm7
	pswapd %mm2, %mm5
	pfmul KP866025403KN866025403, %mm4
	pfmul KP500000000KP500000000, %mm5
	movq %mm1, 8(%esp)
	movq (%eax,%edi), %mm1
	leal (%ebx,%ebx,8), %edi
	movq %mm4, 24(%esp)
	pswapd %mm1, %mm4
	pfadd %mm2, %mm1
	pswapd %mm7, %mm2
	pfsub %mm5, %mm4
	movq (%eax,%ebp), %mm5
	/* simd data load/store barrier */ 
	pfmul KP500000000KP500000000, %mm2
	leal (%ebx,%ebx,4), %ebp
	addl 108(%esp), %eax
	movq %mm4, 40(%esp)
	pswapd %mm5, %mm4
	pfadd %mm7, %mm5
	movq %mm6, %mm7
	pfadd %mm0, %mm6
	pfsub %mm2, %mm4
	movq %mm5, %mm2
	pfadd %mm1, %mm5
	pfsub %mm0, %mm7
	movq 32(%esp), %mm0
	pfsub %mm1, %mm2
	movq %mm6, %mm1
	pfsub %mm5, %mm6
	pfadd %mm5, %mm1
	movq %mm3, %mm5
	pswapd %mm2, %mm2
	pfadd %mm0, %mm3
	pfsub %mm0, %mm5
	movq %mm7, %mm0
	pxor chs_lo, %mm2
	movq %mm6, (%ecx,%esi,2)
	movq 16(%esp), %mm6
	movq %mm1, (%ecx)
	movq 0(%esp), %mm1
	pfsub %mm2, %mm7
	pfadd %mm2, %mm0
	movq %mm6, %mm2
	pfsub %mm1, %mm6
	pfadd %mm1, %mm2
	movq %mm7, (%ecx,%esi)
	movq 8(%esp), %mm7
	leal (%edi,%ebx,2), %esi
	movq %mm0, (%ecx,%edi)
	movq 40(%esp), %mm0
	leal (%ebp,%ebx,2), %edi
	movq %mm6, %mm1
	pfsub %mm5, %mm6
	pfadd %mm5, %mm1
	movq %mm7, %mm5
	pfadd %mm0, %mm7
	pfsubr %mm0, %mm5
	movq %mm7, 48(%esp)
	movq 24(%esp), %mm0
	movq %mm0, %mm7
	pfsubr %mm4, %mm0
	pfadd %mm4, %mm7
	movq %mm0, %mm4
	pfsub %mm5, %mm0
	pfadd %mm5, %mm4
	movq %mm6, %mm5
	pxor chs_lo, %mm0
	pswapd %mm4, %mm4
	pfadd %mm0, %mm5
	pfsub %mm0, %mm6
	movq %mm2, %mm0
	pfsub %mm3, %mm2
	pfadd %mm3, %mm0
	movq %mm1, %mm3
	movq %mm5, (%ecx,%ebp)
	movq 48(%esp), %mm5
	pfsub %mm4, %mm1
	movq %mm6, (%ecx,%esi)
	movq %mm7, %mm6
	pfadd %mm4, %mm3
	movq %mm0, %mm4
	pfsub %mm5, %mm6
	movq %mm1, (%ecx,%ebx,2)
	movq %mm2, %mm1
	pfadd %mm5, %mm7
	pxor chs_lo, %mm6
	movq %mm3, (%ecx,%ebx,8)
	pswapd %mm7, %mm7
	pfadd %mm7, %mm4
	pfsub %mm7, %mm0
	pfadd %mm6, %mm1
	pfsub %mm6, %mm2
	movq %mm4, (%ecx,%ebx,4)
	movq %mm0, (%ecx,%ebp,2)
	movq %mm1, (%ecx,%ebx)
	movq %mm2, (%ecx,%edi)
	addl 112(%esp), %ecx
	decl 104(%esp)
	jnz .L0
	femms 
	movl 72(%esp), %ebx
	movl 68(%esp), %esi
	movl 64(%esp), %edi
	movl 60(%esp), %ebp
	addl $76, %esp
	ret 

.section .rodata
nam:
	.string "n1k7i_12"
	.align 4
desc:
	.long 12
	.long nam
	.double 48
	.double 8
	.double 0
	.double 0
	.long fftwf_kdft_k7_pgenus
	.long 0
	.long 0
	.long 0
	.long 0

.text
	.align 4
.globl fftwf_codelet_n1k7i_12
fftwf_codelet_n1k7i_12:
	subl $12,%esp
	addl $-4,%esp
	pushl $desc
	pushl $n1k7i_12
	pushl 28(%esp)
	call fftwf_kdft_register
	addl $16,%esp
	addl $12,%esp
	ret

